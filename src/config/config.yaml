config:
  llm_model_config:
    creative_model:
      # google/gemini-2.0-flash-001, openai/gpt-oss-120b, x-ai/grok-4-fast
      model_name: openai/gpt-oss-20b
      temperature: 0.2
      max_tokens: 1024
    structured_output_model:
      model_name: openai/gpt-oss-20b
      temperature: 0.0
      max_tokens: 512